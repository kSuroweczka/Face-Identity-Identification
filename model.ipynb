{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Add, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_path = '/content/drive/MyDrive/trainX.pkl'\n",
    "trainy_path = '/content/drive/MyDrive/trainy.pkl'\n",
    "testX_path = '/content/drive/MyDrive/testX.pkl'\n",
    "testy_path = '/content/drive/MyDrive/testy.pkl'\n",
    "\n",
    "def load_data(trainX_path, trainy_path, testX_path, testy_path):\n",
    "    with open(trainX_path, 'rb') as file:\n",
    "        X_train = pickle.load(file)\n",
    "    with open(trainy_path, 'rb') as file:\n",
    "        y_train = pickle.load(file)\n",
    "    with open(testX_path, 'rb') as file:\n",
    "        X_test = pickle.load(file)\n",
    "    with open(testy_path, 'rb') as file:\n",
    "        y_test = pickle.load(file)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(trainX_path, trainy_path, testX_path, testy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labeling and data division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = ['Emilia', 'Joanna', 'Kacper', 'Karolina', 'Mirek', 'Sylwia', '≈Åukasz', 'Mariusz', 'Ania']\n",
    "filtered_train_indices = [i for i, label in enumerate(y_train) if label in valid_labels]\n",
    "filtered_test_indices = [i for i, label in enumerate(y_test) if label in valid_labels]\n",
    "\n",
    "filtered_trainX = np.asarray(X_train)[filtered_train_indices]\n",
    "filtered_testX = np.asarray(X_test)[filtered_test_indices]\n",
    "\n",
    "filtered_trainy = np.asarray(y_train)[filtered_train_indices]\n",
    "filtered_testy = np.asarray(y_test)[filtered_test_indices]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.array(valid_labels)\n",
    "\n",
    "filtered_trainy_encoded = label_encoder.transform(filtered_trainy)\n",
    "filtered_testy_encoded = label_encoder.transform(filtered_testy)\n",
    "\n",
    "label_to_index = {label: idx for idx, label in enumerate(valid_labels)}\n",
    "\n",
    "filtered_trainy_encoded = np.array([label_to_index[label] for label in filtered_trainy])\n",
    "filtered_testy_encoded = np.array([label_to_index[label] for label in filtered_testy])\n",
    "\n",
    "num_classes = len(valid_labels)\n",
    "print(num_classes)\n",
    "filtered_trainy_one_hot = to_categorical(filtered_trainy_encoded, num_classes)\n",
    "filtered_testy_one_hot = to_categorical(filtered_testy_encoded, num_classes)\n",
    "\n",
    "trainX, valX, trainy, valy = train_test_split(filtered_trainX, filtered_trainy_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Architecture and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, units, dropout_rate=0.3):\n",
    "    shortcut = x\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(units, activation=None)(x)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "inputs = Input(shape=(512,))\n",
    "x = Dense(512, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = residual_block(x, 512)\n",
    "x = residual_block(x, 512)\n",
    "x = residual_block(x, 512)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, validation_data=(valX, valy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(filtered_testX, filtered_testy_one_hot)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "\n",
    "y_pred = np.argmax(model.predict(filtered_testX), axis=1)\n",
    "y_true = np.argmax(filtered_testy_one_hot, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=valid_labels, yticklabels=valid_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    '''\n",
    "    Plot confusion matrix\n",
    "    '''\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(len(labels)))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.show()\n",
    "\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    '''\n",
    "    Print accuracy, precision, recall and F1 score\n",
    "    '''\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\nMetrics for {dataset_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    '''\n",
    "    Plot training and validation loss and accuracy\n",
    "    '''\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_true, y_pred, target_names=valid_labels)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "y_train_pred = np.argmax(model.predict(trainX), axis=1)\n",
    "y_train_true = np.argmax(trainy, axis=1)\n",
    "\n",
    "y_val_pred = np.argmax(model.predict(valX), axis=1)\n",
    "y_val_true = np.argmax(valy, axis=1)\n",
    "\n",
    "y_test_pred = np.argmax(model.predict(filtered_testX), axis=1)\n",
    "y_test_true = np.argmax(filtered_testy_one_hot, axis=1)\n",
    "\n",
    "print('Confusion Matrix - Training Set')\n",
    "plot_confusion_matrix(y_train_true, y_train_pred, valid_labels)\n",
    "print_metrics(y_train_true, y_train_pred, 'Training Set')\n",
    "\n",
    "print('Confusion Matrix - Validation Set')\n",
    "plot_confusion_matrix(y_val_true, y_val_pred, valid_labels)\n",
    "print_metrics(y_val_true, y_val_pred, 'Validation Set')\n",
    "\n",
    "print('Confusion Matrix - Test Set')\n",
    "plot_confusion_matrix(y_test_true, y_test_pred, valid_labels)\n",
    "print_metrics(y_test_true, y_test_pred, 'Test Set')\n",
    "\n",
    "class_report = classification_report(y_test_true, y_test_pred, target_names=valid_labels)\n",
    "print(\"\\nClassification Report for Test Set:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
