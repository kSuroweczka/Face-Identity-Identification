{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras_facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = ['Karolina','Kacper','Joanna','Mirek','Sylwia','≈Åukasz','Emilia','Mariusz','Ania'] ## classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_detected_faces_BGR = '/content/drive/MyDrive/Detected_Faces_BGR'\n",
    "def convert_to_BGR(folder_path, data_type, name):\n",
    "  path_save_path = os.path.join(path_to_detected_faces_BGR, data_type, name)\n",
    "  os.makedirs(path_save_path, exist_ok=True)\n",
    "\n",
    "  saved_count = 0\n",
    "  for image_path in os.listdir(folder_path):\n",
    "    img = cv2.imread(os.path.join(folder_path, image_path))\n",
    "    bgr_image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    save_path = os.path.join(path_save_path,f\"cropped_{saved_count:04d}.jpg\")\n",
    "    cv2.imwrite(save_path, bgr_image)\n",
    "    saved_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_no_covering_data = '/content/drive/MyDrive/Detected_Faces/no_covering'\n",
    "for name in persons:\n",
    "    for i in range(1,4):\n",
    "        convert_to_BGR(f'{path_to_no_covering_data}/{name}/{name}_{i}', 'no_covering', f'{name}/{name}_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_no_covering_data = '/content/drive/MyDrive/Detected_Faces/sunglasses'\n",
    "for name in persons:\n",
    "    for i in range(1,4):\n",
    "        convert_to_BGR(f'{path_to_no_covering_data}/{name}/{name}_{i}', 'sunglasses', f'{name}/{name}_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = FaceNet()\n",
    "\n",
    "def get_embeddings(face_img_path):\n",
    "    '''\n",
    "    Function that returns embeddings of face image\n",
    "    :param face_img_path: path to face image\n",
    "    :return: embeddings of face image\n",
    "    '''\n",
    "    face_img = cv2.imread(face_img_path)\n",
    "    face_img = face_img.astype('float32')\n",
    "    face_img = np.expand_dims(face_img, axis=0)\n",
    "    yhat = embedder.embeddings(face_img)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction of facial features without a cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTED_FACES_MAIN_PATH = '/content/drive/MyDrive/Detected_Faces_BGR/no_covering'\n",
    "\n",
    "embeddings_dict = {f\"{name}_{i}\": [] for name in persons for i in range(1, 4)}\n",
    "\n",
    "for name in persons:\n",
    "    for i in range(1, 4):\n",
    "        folder_name = f\"{name}_{i}\"\n",
    "        print(f\"Processing images in folder: {folder_name}\")\n",
    "        \n",
    "        path = os.path.join(DETECTED_FACES_MAIN_PATH, name, folder_name)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Folder not found: {path}\")\n",
    "            continue\n",
    "        \n",
    "        for image_path in os.listdir(path):\n",
    "            embedding = get_embeddings(os.path.join(path, image_path))\n",
    "            embeddings_dict[folder_name].append(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Division of data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = [], []\n",
    "y_train, y_test = [], []\n",
    "\n",
    "for folder, embeddings in embeddings_dict.items():\n",
    "    label = folder.split('_')[0]\n",
    "    \n",
    "    train, test = train_test_split(embeddings, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train.extend(train)\n",
    "    y_train.extend([label] * len(train))\n",
    "    X_test.extend(test)\n",
    "    y_test.extend([label] * len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_path = '/content/drive/MyDrive/trainX.pkl'\n",
    "trainy_path = '/content/drive/MyDrive/trainy.pkl'\n",
    "testX_path = '/content/drive/MyDrive/testX.pkl'\n",
    "testy_path = '/content/drive/MyDrive/testy.pkl'\n",
    "\n",
    "with open(trainX_path, 'wb') as file:\n",
    "    pickle.dump(X_train, file)\n",
    "with open(trainy_path, 'wb') as file:\n",
    "    pickle.dump(y_train, file)\n",
    "with open(testX_path, 'wb') as file:\n",
    "    pickle.dump(X_test, file)\n",
    "with open(testy_path, 'wb') as file:\n",
    "    pickle.dump(y_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extraction of facial features with sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTED_FACES_MAIN_PATH = '/content/drive/MyDrive/Detected_Faces_BGR/sunglasses'\n",
    "SAVE_MAIN_PATH = '/content/drive/MyDrive/'\n",
    "\n",
    "def process_and_save_data(main_path, save_path, persons):\n",
    "    for name in persons:\n",
    "        print(f\"Processing data for: {name}\")\n",
    "        \n",
    "        person_embeddings = []\n",
    "        \n",
    "        for i in range(1, 4): \n",
    "            folder_name = f\"{name}_{i}\"\n",
    "            path = os.path.join(main_path, name, folder_name)\n",
    "            \n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Folder not found: {path}\")\n",
    "                continue\n",
    "            \n",
    "            for image_path in os.listdir(path):\n",
    "                embedding = get_embeddings(os.path.join(path, image_path))\n",
    "                person_embeddings.append(embedding)\n",
    "        \n",
    "        file_path = os.path.join(save_path, f\"testX_{name.lower()}.pkl\")\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pickle.dump(person_embeddings, file)\n",
    "        print(f\"Saved data for {name} to {file_path}\")\n",
    "\n",
    "process_and_save_data(DETECTED_FACES_MAIN_PATH, SAVE_MAIN_PATH, persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
